# 文件解析过滤

## 需求点：

### 1. 设计一套从文件中读取TCP数据、解析数据的接口（TcpFlowReader）

* 支持多种文件格式（json、avro等）的读取；
* 将读取的每一行数据解析成 TcpFlow.java 对象；

### 2. 设计一个库，从tcp flow中过滤指定条件的数据

* 过滤条件支持比较运算：等于、不等于、大于、小于；
* 支持上述条件的与、或、非逻辑运算，支持混合运算；
* 暂不用解析过滤条件表达式，可以通过API生成复杂的匹配条件；

### 3. 在上面的基础上，实现如下过滤功能，并将命中的tcp flow数据包打印出来：

src_ip = '10.1.199.6' && dst_ip = '10.1.196.1' && session_state != 4 && (down_pkts > 100 || down_pkts < 300)

### 扩展思考：
1、如何在修改代码最少的情况下，增加对csv文件格式读取的支持；
2、怎么设计框架，支持动态扩展过滤条件。可以在不侵入原有代码的条件下，方便第三方自定义过滤条件。
比如：支持正则表达式匹配。


## 注意点：

1. 对底层文件的操作和解析要解耦；

    做法：将读取文件和解析tcp日志的逻辑抽象成接口，接口返回读取和解析好的 TcpFlow.java 对象，上层应用只看到 TcpFlow.java 对象，不关心数据的来源和存储格式，数据源对上层应用是透明的。

2. 过滤表达式的解析和匹配过程解耦；

    做法：构建表达式解析树，作为匹配过程的输入。也就是说，匹配过程只根据表达式解析树对数据包进行匹配操作。匹配过程不关心表达式是如何解析的，表达式的语法是什么样的。

    本次练习直接通过API创建表达式树，不用做语法解析。

3. 数据包的过滤匹配需要封装，对外隐藏匹配细节，只返回匹配到的数据包供上层处理；

4. 考虑如果设计才能方便的扩展对更多运算符的支持，不改动现有代码，第三方开发人员可以方便的自己实现一个运算符并注册进来；

5. 划分好类，做好职责分工，每个类最好只关注一件事情，方便单元测试；

6. avro文件的解析可参考：http://avro.apache.org/docs/current/gettingstartedjava.html。

7. json的解析可以使用Jackson、Fastjson等。

## TCP数据包字段如下：
{
	"uid": "C7mGqkFy5Lre1gj36gXiPhb",
	"src_ip": "10.1.193.36",
	"dst_ip": "10.1.5.50",
	"dst_port": 80,
	"src_port": 61884,
	"session_state": 4,
	"up_linklength": 499,
	"down_linklength": 365,
	"up_applength": 217,
	"down_applength": 137,
	"up_pkts": 5,
	"down_pkts": 4,
	"src_mac": "74:ea:c8:28:14:01"
	"dst_mac": "00:00:00:00:00:00",
	"proto": "http",
	"ts": 1595272023,
}

